---
title: "이미지 분할 해보기: 시맨틱 분할"
description: ""
tags: ["Tensorflow","Tutorial","ML"]
date: "2023-01-20"
thumbnail: "/markdown-memo/legacy/images/4683a032-1496-4329-8d97-519243273a06.png"
---


**시맨틱 분할**이란?

이미지안에 고양이가 존재한다면 각 픽셀이 독립적으로 고양이와 같은 하나의 의미를 가진 범주로 분류됩니다. 이미지 안에 여러마리의 고양이들이 존재한다면 이에 해당하는 모든 픽셀은 동일한 ‘cat’  범주로 매핑됩니다.


사용한 데이터 셋

Oxfod-IIIT Pets 데이터 셋은 다양한 품종의 고양이와 강아지 사진 7390개와 각 사진의 전경-배경 분할 마스크를 포함하고 있습니다.

분할 마스크는 이미지 분할에서 레이블에 해당됩니다. 입력 이미지와 동일한 크기의 이미지고 컬러 채널은 하나입니다.


<!-- Unknown block type: column_list -->

고양이 이미지와 마스킹된 고양이 이미지


코랩에서는 해당 명령을 사용하여 데이터 셋을 가져올 수 있습니다.

```python
!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz
!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz
!tar -xf images.tar.gz
!tar -xf annotations.tar.gz
```


```python
import os
input_dir = 'images/'
target_dir = 'annotations/trimaps'

input_img_paths = sorted([os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith('.jpg')])
target_img_paths = sorted([os.path.join(target_dir, fname) for fname in os.listdir(target_dir) if fname.endswith('.png') 
  and not fname.startswith('.')])
```

input_img_paths와 target_img_paths 변수는 각각 입력과 타겟 이미지의 경로입니다.

해당 주소를 통하여 이미지 객체를 받아온 후 입력 이미지는 부동소수점 텐서로, 타겟 이미지는 정수 텐서로 적절하게 변환 할 것입니다.

```python
import matplotlib.pyplot as plt
from tensorflow.keras.utils import img_to_array, load_img
```

load_img() 메서드를 통하여 이미지 경로로부터 이미지 객체를 가져오고 img_to_array() 메서드로 텐서 형태로 변환 할 것입니다.

```python
import numpy as np
import random

img_size = (200, 200) # 입력 크기는 200 x 200
num_imgs = len(input_img_paths)

random.Random(2323).shuffle(input_img_paths) 
random.Random(2323).shuffle(target_img_paths)
"""
랜덤 시드를 같게 설정하여 섞여도 입력과 출력 이미지가 서로 같도록 만든다.
"""

def path_to_input_image(path):
  return img_to_array(load_img(path, target_size=img_size))

def path_to_target_image(path):
  return img_to_array(load_img(path, target_size=img_size, color_mode='grayscale')).astype('uint8') - 1
"""
출력 이미지는 초기에 1, 2, 3 (1 -> 전경, 2 -> 배경, 3 -> 윤곽)으로 설정되어 있으므로
출력 레이블로 적절하게 만들어 주기 위해서 정수 텐서로 변환 후 1을 뺐다.
"""

input_imgs = np.zeros((num_imgs, ) + img_size + (3, ), dtype='float32')
# 이미지개수 x 200 x 200 x 3(RGB값)
targets = np.zeros((num_imgs, ) + img_size + (1, ), dtype='uint8')
# 이미지개수 x 200 x 200 x 1(0, 1, 2 중 하나)

for i in range(num_imgs):
  input_imgs[i] = path_to_input_image(input_img_paths[i])
  targets[i] = path_to_target_image(target_img_paths[i])
```

사이킷런의 model_selection 모듈을 활용하여 검증데이터와 훈련데이터로 나누겠습니다.

본인의 경우 코랩에서 해당 모델을 실행하였는데 모델 학습 도중에 메모리를 초과하여 필요없다고 판단되는 로컬 변수들은 메모리를 해제 시켜줬습니다.

```python
from sklearn.model_selection import train_test_split
import gc

train_images, test_images, train_targets, test_targets = train_test_split(input_imgs, targets, test_size=0.2)

"""
개발 환경의 메모리가 충분하다면 굳이 사용할 필요가 없다!

del(input_imgs)
del(targets)
del(input_img_paths)
del(target_img_paths)
gc.collect()

"""
```


# 모델 구성하기

충분한 데이터 전처리를 마친 후 이제 모델을 구성해보자

```python
from tensorflow import keras
from tensorflow.keras import layers

def get_model(img_size, num_classes):
  inputs = keras.Input(shape=img_size + (3, ))
  x = layers.Rescaling(1./255)(inputs)
  x = layers.Conv2D(16, 3, strides=2, activation='relu', padding='same')(x)
  x = layers.Conv2D(16, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, strides=2, activation='relu', padding='same')(x)
  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2D(64, 3, strides=2, activation='relu', padding='same')(x)
  x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)

  x = layers.Conv2DTranspose(64, 3, activation='relu', padding='same')(x)
  x = layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)
  x = layers.Conv2DTranspose(32, 3, activation='relu', padding='same')(x)
  x = layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)
  x = layers.Conv2DTranspose(16, 3, activation='relu', padding='same')(x)
  x = layers.Conv2DTranspose(16, 3, strides=2, activation='relu', padding='same')(x)

  outputs = layers.Conv2D(num_classes, 3, activation='softmax', padding='same')(x)

  model = keras.Model(inputs=inputs, outputs=outputs)
  return model
```

본인의 경우 앞서 언급했듯이 메모리 문제로 모델의 크기를 많이 줄였는데 각 층별 유닛의 크기를 두 배 이상씩 증가시키면 더욱 정확한 모델을 만들 수 있을 것입니다.

스케일링을 통하여 0~255 사이의 RGB 값을 0 ~ 1로 바꿔준 후, 합성곱 층을 사용하여 모델을 구성하였습니다.

그 과정에서 마지막 합성곱 층까지 총 3번의 다운샘플링을 통하여 모델을 구성하였는데, 기존의 CNN 모델과 달리 최대 풀링 층을 전혀 사용하지 않고 스트라이드 만을 이용하여 다운샘플링을 진행하였습니다.

그 이유는 우리가 해결하고자 하는 문제 특성상 출력 값으로 픽셀별 타깃 마스크를 생성해야 하는데 최대 풀링 층을 사용하여 다운샘플링을 진행하면 풀링 윈도우 안의 위치 정보가 완전히 삭제됨으로 픽셀별 타깃 마스크를 생성하는데 비효율적이기 때문입니다.


마지막 합성곱 층이 지난 후, 입력 이미지와 똑같은 크기의 출력 타깃 마스크를 생성하기 위해서는 지금까지 적용한 변환을 거꾸로 할 필요가 있습니다. 즉 특성맵을 **업샘플링 **해야합니다.


```python
model = get_model(img_size, 3)
model.compile(
    optimizer='rmsprop',
    loss='sparse_categorical_crossentropy'
)

callbacks = [
    keras.callbacks.ModelCheckpoint(
        save_best_only=True,
        filepath='oxford_segmentation.keras'
    )
]

history = model.fit(train_images,
                    train_targets,
                    validation_data=(test_images, test_targets),
                    epochs=50,
                    callbacks=callbacks,
                    batch_size=32)
```

타겟 이미지의 텐서가 레이블(0, 1, 2….)로 이루어져 있으므로 레이블과 원-핫 인코딩되어 있는 출력 값 사이의 손실값을 계산할 수 있도록 하는 sparse_categorical_crossentropy를 손실함수로 설정하였습니다.

콜백함수로 ModelCheckpoint를 설정하여 검증 손실 값이 가장 낮은 모델을 저장하도록 하였습니다.


학습 간 훈련데이터와 검증데이터의 손실 그래프는 이러합니다.

![](/markdown-memo/legacy/images/4683a032-1496-4329-8d97-519243273a06.png)

25~30 에포크근처에서 과대적합이 일어나는 것을 볼 수 있습니다.

```python
loaded_model = keras.models.load_model('oxford_segmentation.keras')

def show_img_and_mask(index):
  plt.axis('off')
  plt.title('input image')
  plt.imshow(test_images[index] / 255)
  predict = loaded_model.predict(np.expand_dims(test_images[index], 0))[0]
  mask = np.argmax(predict, axis=-1)
  mask *= 127
  plt.figure()
  plt.axis('off')
  plt.title('prediction mask')
  plt.imshow(mask)
  plt.figure()
  plt.axis('off')
  plt.title('answer mask')
  plt.imshow(test_targets[index][:, :, 0])

show_img_and_mask(444)
```

학습 간 최고의 모델을 로드한 후, 이미지와 예측 마스크 그리고 정답 마스크를 보여주는 메서드를 작성하였습니다.

<!-- Unknown block type: column_list -->

# 매듭짓기

- 최대 풀링 층을 이용한 다운샘플링은 분류 작업에서 탁월하지만, 분할 작업에는 적절하지 않습니다. 따라서 여기에서는 스트라이드를 활용하여 다운샘플링을 진행해야 합니다.
- 이미지 분할 문제의 경우 입력과 출력 이미지의 크기가 동일해야 합니다.
- 최대 풀링 층의 경우 윈도우 내부의 위치 정보를 완전히 없애버리므로 특성 맵에서 위치 정보가 필요한 문제의 경우 최대 풀링을 사용하면 안됩니다.

