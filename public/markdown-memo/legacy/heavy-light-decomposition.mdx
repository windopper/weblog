---
title: "Heavy-Light Decomposition"
description: ""
tags: ["Algorithm","Segment Tree"]
date: "2023-04-21"
thumbnail: ""
---

# 개요

Heavy-Light Decomposition(이하 HLD)는 트리를 여러 개의 체인으로 분할하여 임의의 두 정점 사이의 경로에 최대 logN개의 체인만 존재하도록 하는 자료구조입니다.

HLD의 Heavy와 Light의 의미는 간선들을 무거운(Heavy)과 가벼운(Light) 간선으로 구분하는 것인데, 여기서는 이 무게에 대한 기준을 “서브 트리의 크기”를 기준으로 구분합니다.

부모 정점 u에서 자식 정점 v로 가는 간선 (u, v)가 있을 때 v의 서브 트리 크기가 u의 서브 트리 크기의 절반 이상인 경우 그 간선을 heavy edge라고 하고, 나머지 간선들을 light edge라고 합니다.

또한 한 정점에서 내려가는 heavy edge는 최대 한 개만 존재해야 합니다.

# 구현

```c++

#include <bits/stdc++.h>

using namespace std;

struct Seg {
    int tree[1<<18];
    int sz = 1 << 17;

    void update(int x, int v) {
        x |= sz;
        tree[x] += v;
        while(x >>= 1) {
            tree[x] = tree[x<<1] + tree[x<<1 | 1];
        }
    }

    int query(int l, int r) {
				// 리프 노드에 접근하기 위해서는 트리 전체 크기의 절반을 더해줘야 함
        l |= sz;
        r |= sz;
        int ret = 0;
        while(l <= r) {
            if(l & 1) ret += tree[l++];
            if(~r & 1) ret += tree[r--];
            l >>= 1, r >>= 1;
        }
        return ret;
    }
} seg;

const int MAXV = 400000;
int sz[MAXV], dep[MAXV], par[MAXV], top[MAXV], in[MAXV], out[MAXV];
vector<int> g[MAXV];
int pv = 0;

/*
sz[i] = i를 루트로 하는 서브트리의 크기
dep[i] = i의 깊이
par[i] = i의 부모 정점
top[i] = i가 속한 체인의 가장 위에 있는 정점
in[i], out[i] = dfs ordering
g[i] = i의 자식 정점
*/

void dfs1(int v = 1) {
    sz[v] = 1;
    for(auto &i : g[v]) {
        // 깊이 증가
        dep[i] = dep[v] + 1;
        // 부모 설정
        par[i] = v;
        dfs1(i);
        // 서브트리 크기 증가
        sz[v] += sz[i];
        // 서브 트리가 가장 큰 자식을 g[v]의 맨 앞으로 이동
        // 따라서 v에서 뻗어나가는 heavy edge는 g[v][0]가 됨
        if(sz[i] > sz[g[v][0]]) swap(i, g[v][0]);
    }
}

// dfs ordering
void dfs2(int v = 1) {
    in[v] = ++pv;
    for(auto i : g[v]) {
        // i 가 g[v]의 첫번째 자식이라면 top[v]를 물려받음
        // 그렇지 않다면 새로운 체인 시작
        top[i] = i == g[v][0] ? top[v] : i;
        dfs2(i);
    }
    out[v] = pv;
}

int query(int a, int b) {
    int ret = 0;
    // 서로 다른 종류의 체인인 경우
    while(top[a] ^ top[b]) {
        // a의 깊이가 더 깊어야 한다.
        if(dep[top[a]] < dep[top[b]]) swap(a, b);
        // a가 속한 체인의 시작점
        int st = top[a];
        // 같은 체인에 대하여 쿼리를 날림
        ret += seg.query(in[st], in[a]);
        // a가 체인의 시작점의 부모가 된다.
        a = par[st];
    }
    // a의 깊이가 더 깊어야 한다.
    if(dep[a] > dep[b]) swap(a, b);
    // 
    ret += seg.query(in[a], in[b]);
    return ret;
}
```


# 예제

[https://www.acmicpc.net/problem/13510](https://www.acmicpc.net/problem/13510)

  <details>
  <summary>코드</summary>

</details>


[https://www.acmicpc.net/problem/13512](https://www.acmicpc.net/problem/13512)

  <details>
  <summary>코드</summary>

</details>

세그먼트 트리를 이용하여 K번째 수를 구하는 테크닉과 기본적인 Heavy-Light Decomposition을 섞은 문제이다.


[https://www.acmicpc.net/problem/2927](https://www.acmicpc.net/problem/2927)

  <details>
  <summary>코드</summary>

  <details>
  <summary>코드2</summary>

  </details>

HLD + 유니온 파인드 + 오프라인 쿼리를 이용해야 되는 문제.

쿼리 순서대로 다리를 지으며 경로에 대해 펭귄의 수를 구하면 O(NQ)의 시간이 걸려 시간초과가 난다. 

따라서 다리를 짓는 명령에 대한 답변을 하기 위해서 유니온 파인드 자료구조를 이용하고 excursion 명령에 대해서는 유니온 파인드의 find 메서드를 이용하여 impossible 여부만 따로 저장한다.

모든 쿼리를 받고 만들어진 다리들은 포레스트일 수 도 있기 때문에 모든 노드에 대해서 hld를 만들기 위해 1번부터 N번까지 순회하며 dfs를 해주었다.

그 후, penguins 명령의 업데이트와 excursion명령의 트리의 구간 쿼리는 hld가 제일 잘하는 것이다.

시간복잡도는 O(Qlog^2N)

# References

[https://justicehui.github.io/hard-algorithm/2020/01/24/hld/](https://justicehui.github.io/hard-algorithm/2020/01/24/hld/)

